{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previous: <a href = \"keras_07.ipynb\">1.7 Batch size and number of epochs</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Keras </center>\n",
    "## <center>1.8 Loss function</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Loss function\n",
    "Another way to improve the model is to change the loss function.<br>\n",
    "<img src=\"img/structure_loss.PNG\" width=\"60%\" />\n",
    "For different problems there are better suiting functions:\n",
    "<img src=\"img/LossFunction.PNG\" width = \"70%\" />\n",
    "Some of them were mathematically proven to be good. Others were only observed to suit best for a certain kind of problem.<br>\n",
    "Other functions:\n",
    " - mean_absolute_error\n",
    " - mean_absolute_percentage_error\n",
    " - mean_squared_logarithmic_error\n",
    " - squared_hinge\n",
    " - hinge\n",
    " - categorical_hinge\n",
    " - logcosh\n",
    " - sparse_categorical_crossentropy\n",
    " - kullback_leibler_divergence\n",
    " - poisson\n",
    " - cosine_proximity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#previously done\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.optimizers import SGD, Adam, Adamax\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.datasets import mnist\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "%matplotlib inline\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import SVG\n",
    "#Load MNIST\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "#Reshape\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)\n",
    "#Split\n",
    "X_train = X_train[0:10000]\n",
    "X_test = X_test[0:1000]\n",
    "Y_train = Y_train[0:10000]\n",
    "Y_test = Y_test[0:1000]\n",
    "\n",
    "def plot_training_history(history):\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    #loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(input_dim=28*28, units=500, activation='sigmoid'))\n",
    "model.add(Dense(units=500, activation='sigmoid'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "BATCH_SIZE=100\n",
    "NP_EPOCHS = 5\n",
    "\n",
    "model.compile(loss='mse',\n",
    "              optimizer=SGD(lr=0.1),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=BATCH_SIZE, epochs=NP_EPOCHS,\n",
    "                    verbose=1, validation_data=(X_test, Y_test))\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task\n",
    "Try out four different loss functions and see which one performs better<br>\n",
    " - mean_absolute_error\n",
    " - mean_absolute_percentage_error\n",
    " - mean_squared_logarithmic_error\n",
    " - squared_hinge\n",
    " - hinge\n",
    " - categorical_hinge\n",
    " - logcosh\n",
    " - sparse_categorical_crossentropy\n",
    " - kullback_leibler_divergence\n",
    " - poisson\n",
    " - cosine_proximity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next: <a href = \"keras_09.ipynb\">1.9 Optimizer</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "livereveal": {
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
