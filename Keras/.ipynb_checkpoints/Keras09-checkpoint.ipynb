{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Keras </center>\n",
    "## <center>1.6.1 Loss functions</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function (or objective function) is the quantity that will be minimized during training. It represents a measure of success on the task at hand.\n",
    "\n",
    "<img src=\"img/structure_loss.PNG\" width=\"60%\" />\n",
    "For different problems there are better suiting functions:\n",
    "<img src=\"img/LossFunction.PNG\" width = \"70%\" />\n",
    "Some of them were mathematically proven to be good. Others were only observed to suit best for a certain kind of problem.<br>\n",
    "Other functions:\n",
    " - mean_absolute_error\n",
    " - mean_absolute_percentage_error\n",
    " - mean_squared_logarithmic_error\n",
    " - squared_hinge\n",
    " - hinge\n",
    " - categorical_hinge\n",
    " - logcosh\n",
    " - sparse_categorical_crossentropy\n",
    " - kullback_leibler_divergence\n",
    " - poisson\n",
    " - cosine_proximity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us run the code from the previous section first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the MNIST dataset\n",
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Processing the input data\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "# Processing the output data\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "# Build a network\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(units=512, activation='relu', input_shape=(28 * 28,)))\n",
    "network.add(layers.Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now examine the code related to compiling a network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile the network\n",
    "network.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are using `rmsprop` as the optimizer and `categorical_crossentropy` as the loss function. The performance metric is `accuracy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_training_history(history):\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    #loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the network\n",
    "history = network.fit(train_images, train_labels, epochs=5, batch_size=128, \n",
    "                      verbose=1, validation_data=(test_images, test_labels))\n",
    "\n",
    "# Plot the training results\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task\n",
    "Try out four different loss functions and see which one performs better<br>:\n",
    "\n",
    "- mean_absolute_error\n",
    "- mean_absolute_percentage_error\n",
    "- mean_squared_logarithmic_error\n",
    "- squared_hinge\n",
    "- hinge\n",
    "- categorical_hinge\n",
    "- logcosh\n",
    "- sparse_categorical_crossentropy\n",
    "- kullback_leibler_divergence\n",
    "- poisson\n",
    "- cosine_proximity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "In this section we learned about the loss functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Feedback\n",
    "<a href = \"http://goto/ml101_doc/Keras09\">Feedback: Loss functions</a> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation\n",
    "\n",
    "<div>\n",
    "<span> <h3 style=\"display:inline\">&lt;&lt; Prev: <a href = \"keras08.ipynb\">Compile a network</a></h3> </span>\n",
    "<span style=\"float: right\"><h3 style=\"display:inline\">Next: <a href = \"keras10.ipynb\">Optimizers</a> &gt;&gt; </h3></span>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
