{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Keras </center>\n",
    "## <center>1.9 Dropout</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout\n",
    "\n",
    "Dropout is a technique that reduces the complexity of a model.<br>\n",
    "It helps protect the model from memorizing or \"overfitting\" the training data.\n",
    "Dropout, applied to a layer, consists of randomly \"dropping out\" (i.e. setting to zero) a\n",
    "number of output features of the layer during training.\n",
    "<img src=\"img/Dropout.jpg\"  width=\"600\"/>\n",
    "<img src=\"img/dropout.png\"  width=\"600\"/>\n",
    "\n",
    "Through dropout the network can't always relay on all of its knowledge, thus it has to classify with less nodes. This makes the whole network more robust and prevents overfitting.<br><br>\n",
    "Dropout helps to improve the accuracy when there is not much data to train on.<br>\n",
    "As not every layer is fully connected to the next one, less computing cost is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pitfall\n",
    "\n",
    "A Fully conected network is not always better "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing the MNIST dataset\n",
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Processing the input data\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "# Processing the output data\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "# Build a network\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(units=512, activation='relu', input_shape=(28 * 28,)))\n",
    "# model.add(Dropout(0.2))\n",
    "network.add(layers.Dense(units=10, activation='softmax'))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# Compile the network\n",
    "network.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# Train the network\n",
    "history = network.fit(train_images, train_labels, epochs=5, batch_size=128, \n",
    "                      verbose=1, validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_training_history(history):\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    #loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the training results\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task\n",
    "\n",
    "- Uncomment the dropout lines in the code to see the effect on the prediction accuracy.\n",
    "- Try out the following dropout-rates and document the results:\n",
    "    a) 0.1\n",
    "    b) 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedback\n",
    "<a href = \"http://goto/ml101_doc/Keras14\">Feedback: Dropout</a> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<span> <h3 style=\"display:inline\">&lt;&lt; Prev: <a href = \"Keras13.ipynb\">Overfitting</a></h3> </span>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
