{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previous: <a href = \"keras_05.ipynb\">1.5 Overfitting VS generalization</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Keras </center>\n",
    "## <center>1.6 Increasing/Decreasing number of layers</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation\n",
    "There are three types of layers:\n",
    "- input layer\n",
    "- hidden layer\n",
    "- output layer\n",
    "\n",
    "One hidden layer is sufficient for the large majority of problems.\n",
    "\n",
    "There is no \"magic\" rule to calculate the number of hidden layers and nodes of Neural Network, but there are some tips and recommendations.\n",
    "\n",
    "The number of hidden nodes is based on a relationship between:\n",
    "\n",
    "- Number of input and output nodes\n",
    "- Amount of training data available\n",
    "- Complexity of the function that is trying to be learned\n",
    "- The training algorithm\n",
    "- To minimize the error and have a trained network that generalizes well, you need to pick an optimal number of hidden layers, as well as nodes in each hidden layer.\n",
    "\n",
    "- Too few nodes will lead to high error for your system as the predictive factors might be too complex for a small number of nodes to capture\n",
    "\n",
    "- Too many nodes will overfit to your training data and not generalize well\n",
    "\n",
    "<img src=\"img/hiddenlayers.png\" width=\"60%\" />\n",
    "\n",
    "<img src=\"img/structure_layer.PNG\" width=\"60%\" />\n",
    "\n",
    "## Bad practice\n",
    "Adding to many layers won't necessarily increase your accuracy. It may lead to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#previously done\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.optimizers import SGD, Adam, Adamax\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "%matplotlib inline\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import SVG\n",
    "#Load MNIST\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "#Reshape\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)\n",
    "#Split\n",
    "X_train = X_train[0:10000]\n",
    "X_test = X_test[0:1000]\n",
    "Y_train = Y_train[0:10000]\n",
    "Y_test = Y_test[0:1000]\n",
    "\n",
    "def plot_training_history(history):\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    #loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(input_dim=28*28, units=500, activation='relu'))\n",
    "model.add(Dense(units=500, activation='relu'))\n",
    "model.add(Dense(units=500, activation='relu'))\n",
    "model.add(Dense(units=500, activation='relu'))\n",
    "model.add(Dense(units=500, activation='relu'))\n",
    "model.add(Dense(units=500, activation='relu'))\n",
    "model.add(Dense(units=500, activation='relu'))\n",
    "model.add(Dense(units=500, activation='relu'))\n",
    "model.add(Dense(units=500, activation='relu'))\n",
    "model.add(Dense(units=500, activation='relu'))\n",
    "model.add(Dense(units=500, activation='relu'))\n",
    "model.add(Dense(units=500, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='mse',\n",
    "              optimizer=SGD(lr=0.1),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "BATCH_SIZE=100\n",
    "NP_EPOCHS=10\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=BATCH_SIZE, epochs=NP_EPOCHS,\n",
    "                    verbose=1, validation_data=(X_test, Y_test))\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(input_dim=28*28, units=500, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='mse',\n",
    "              optimizer=SGD(lr=0.1),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "BATCH_SIZE=100\n",
    "NP_EPOCHS=10\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=BATCH_SIZE, epochs=NP_EPOCHS,\n",
    "                    verbose=1, validation_data=(X_test, Y_test))\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task\n",
    "Compare the graphs of the two results regarding their number of layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Next: <a href = \"keras_07.ipynb\">1.7 Batch size and number of epochs</a>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "livereveal": {
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
